import os
import sys
import subprocess
import numpy as np
import deepchem as dc
from rdkit import Chem
from rdkit.Chem import AllChem, rdFingerprintGenerator
from sklearn.model_selection import KFold
from sklearn.preprocessing import StandardScaler
from skopt import gp_minimize
from skopt.space import Real, Integer
from skopt.utils import use_named_args
import random


# sys.path.append("./arpeggio") # Not needed for mock implementation


# ----------------- DATA SETUP -----------------
smiles_list = [
    "C=CCN1CC[C@]23[C@@H]4C(=O)CC[C@]2([C@H]1CC5=C3C(=C(C=C5)O)O4)O", # OORM 1 (e.g., Oxymorphone derivative)
    "C=C1CC[C@]2([C@H]3CC4=C5[C@]2([C@H]1OC5=C(C=C4)O)CCN3CC6CC6)O", # OORM 2 (e.g., Naltrexone derivative)
    "C1CC1CN2CC[C@]34[C@@H]5C(=O)CC[C@]3([C@H]2CC6=C4C(=C(C=C6)O)O5)O"  # OORM 3 (e.g., Cyclazocine derivative)
]
binding_affinities = [1.0, 1.0, 0.5]


morgan_gen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)
mols = [Chem.MolFromSmiles(s) for s in smiles_list]
X = np.array([np.array(morgan_gen.GetFingerprint(m)) for m in mols], dtype=float)
scaler = StandardScaler()
y = scaler.fit_transform(np.array(binding_affinities).reshape(-1, 1)).flatten()


# ----------------- MODIFICATION FEATURE -----------------
def generate_modified_smiles(base_smiles_list, num_modifications_per_drug=1):
    modified_smiles = []
   
    # Define simple mock modifications to simulate adding bulk/change
    modifications = ['C', 'Cl', 'F'] # Adding a C, Chlorine, or Fluorine atom/group
   
    for base_smiles in base_smiles_list:
        for _ in range(num_modifications_per_drug):
           
            # 1. Choose a random insertion point (index) in the SMILES string
            insertion_index = random.randint(0, len(base_smiles) - 1)
           
            # 2. Choose a random modification
            mod = random.choice(modifications)
           
            # 3. Insert the modification (this often creates invalid SMILES, which RDKit handles later)
            new_smiles = base_smiles[:insertion_index] + mod + base_smiles[insertion_index:]
           
            modified_smiles.append(new_smiles)
           
    # Filter out candidates that RDKit cannot parse (often created by the string manipulation)
    valid_modified_smiles = [s for s in modified_smiles if Chem.MolFromSmiles(s) is not None]
   
    return valid_modified_smiles


# ----------------- MODEL OPTIMIZATION AND TRAINING -----------------


space = [
    Real(1e-5, 1e-2, name='learning_rate', prior='log-uniform'),
    Real(0.1, 0.5, name='dropouts'),
    Integer(100, 2000, name='layer1_size'),
    Integer(100, 2000, name='layer2_size'),
    Integer(100, 2000, name='layer3_size'),
]


@use_named_args(space)
def objective(learning_rate, dropouts, layer1_size, layer2_size, layer3_size):
    n_tasks = 1
    n_features = 2048
    epochs = 30
    kf = KFold(n_splits=2, shuffle=True, random_state=42)
    maes = []
    for tr, va in kf.split(X):
        X_train, X_val = X[tr], X[va]
        y_train, y_val = y[tr], y[va]
        train = dc.data.NumpyDataset(X_train, y_train)
        val = dc.data.NumpyDataset(X_val, y_val)
        model = dc.models.MultitaskRegressor(
            n_tasks=n_tasks,
            n_features=n_features,
            layer_sizes=[layer1_size, layer2_size, layer3_size],
            dropouts=float(dropouts),
            learning_rate=learning_rate,
            dtype=X.dtype
        )
        model.fit(train, nb_epoch=epochs)
        metric = dc.metrics.Metric(dc.metrics.mae_score)
        score = model.evaluate(val, [metric], transformers=[])
        maes.append(score["mae_score"])
    return np.mean(maes)


print("Running Bayesian optimization to find best hyperparameters...")
res = gp_minimize(objective, space, n_calls=10, random_state=42)
best_lr, best_drop, l1, l2, l3 = res.x
print(f"Optimal Hyperparameters: LR={best_lr:.6f}, Dropout={best_drop:.3f}")


final_model = dc.models.MultitaskRegressor(
    n_tasks=1,
    n_features=2048,
    layer_sizes=[l1, l2, l3],
    dropouts=best_drop,
    learning_rate=best_lr,
    dtype=X.dtype
)
dataset = dc.data.NumpyDataset(X, y)
final_model.fit(dataset, nb_epoch=40)
print("Final ML model trained.")


# ----------------- SCREENING FUNCTIONS -----------------


def screen_with_ml_model(model, scaler, candidate_smiles_list):
    mols_to_predict = [Chem.MolFromSmiles(s) for s in candidate_smiles_list]
   
    valid_mols = [m for m in mols_to_predict if m is not None]
    valid_smiles = [s for s, m in zip(candidate_smiles_list, mols_to_predict) if m is not None]
   
    if not valid_mols:
        return []


    X_pred = np.array([np.array(morgan_gen.GetFingerprint(m)) for m in valid_mols], dtype=float)
   
    y_pred_normalized = model.predict(dc.data.NumpyDataset(X_pred))
   
    # Fix for ValueError: reshape 3D to 2D for scaler, then flatten to 1D
    y_pred_real = scaler.inverse_transform(y_pred_normalized.reshape(-1, 1)).flatten()
   
    candidate_scores = list(zip(valid_smiles, y_pred_real))
   
    candidate_scores.sort(key=lambda x: x[1])
   
    return candidate_scores


def is_toxic(smiles):
    return np.random.rand() > 0.8


def smiles_to_pdb(smiles, out_file="ligand.pdb"):
    mol = Chem.MolFromSmiles(smiles)
    if mol is None: return None
    mol = Chem.AddHs(mol)
    AllChem.EmbedMolecule(mol, AllChem.ETKDG())
    AllChem.UFFOptimizeMolecule(mol)
    Chem.MolToPDBFile(mol, out_file)
    return out_file


def run_arpeggio(pdb_file_path):
    # MOCK IMPLEMENTATION: Simulating the successful Arpeggio output
    print(f"\nArpeggio Mock Result for {pdb_file_path}:")
    print("  SIMULATED: Non-covalent interaction profile confirmed. ")
    print("  SIMULATED: 4 Hydrogen bonds, 2 Pi-Cation interactions, suggesting long residency time.")


def run_molecular_docking(receptor_pdb_file, smiles_string):
    docking_score = np.random.uniform(-10, -5)
    return docking_score


# ----------------- MAIN WORKFLOW -----------------


if __name__ == "__main__":
    receptor_pdb = "8EF5 (1).pdb"
    baseline_smiles = "C1CCN(CC1)CCC(=O)NC2=CC=C(C=C2)C3=CC=CC=C3"
    baseline_score = run_molecular_docking(receptor_pdb, baseline_smiles)
   
    print("\nStarting Drug Screening Workflow")
    print(f"Fentanyl Baseline Mock Docking Score: {baseline_score:.3f} (Lower is better)")
   
    # --- NEW FEATURE: Generate Modified Candidates for Screening ---
    # Uncomment the two lines below to screen the randomized, modified drugs instead
    # candidates_to_screen = generate_modified_smiles(smiles_list, num_modifications_per_drug=5)
   
    # --- Current Feature: Screening the original training data as candidates ---
    candidates_to_screen = smiles_list
   
    print(f"Using {len(candidates_to_screen)} molecules for screening.")
   
    predicted_candidates = screen_with_ml_model(final_model, scaler, candidates_to_screen)
   
    viable_candidates = predicted_candidates
   
    print(f"\nProcessing {len(viable_candidates)} Candidates Predicted by ML:")


    final_candidates = []
   
    for i, (new_smiles, predicted_score) in enumerate(viable_candidates):
        print(f"\nCandidate {i+1} ({new_smiles})")
       
        if is_toxic(new_smiles):
            print(f"Skipping due to Mock Toxicity Risk.")
            continue


        print(f"ML Predicted Score: {predicted_score:.3f} (Lower is better)")
       
        print("Running final structural validation (3D prep and Arpeggio)...")
        ligand_pdb = smiles_to_pdb(new_smiles, out_file=f"candidate_{i+1}_ligand.pdb")
       
        if ligand_pdb:
            run_arpeggio(ligand_pdb)
            final_candidates.append(new_smiles)
        else:
            print("Could not generate 3D structure (RDKit error). Skipping.")


    print("\n==============================================")
    print(f"Final Viable Candidates (Passed ML and Validation): {len(final_candidates)}")
    print("==============================================")
